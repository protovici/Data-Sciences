{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "tq() ### Library Importing Is Complete. ###: 100%|██████████| 20/20 [00:10<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####  IMPORTS COMPLETE  #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, plot_confusion_matrix, confusion_matrix, f1_score\n",
    "from statistics import mean\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Dropout\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm as tq\n",
    "import time\n",
    "for i in tq(range(20), desc = 'tq() ### Library Importing Is Complete. ###'):\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print('#####  IMPORTS COMPLETE  #####')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset ='train', \n",
    "                             remove=('headers', 'footers', 'quotes'), \n",
    "                             shuffle=True, \n",
    "                             random_state=42)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = dataset.data\n",
    "df['source'] = dataset.target\n",
    "\n",
    "label = []\n",
    "\n",
    "for i in df['source']:\n",
    "    label.append(dataset.target_names[i])\n",
    "\n",
    "df['label']=label\n",
    "\n",
    "# Remove source feature as label will be encoded for dependant:\n",
    "df.drop(['source'], axis = 1, inplace = True)\n",
    "\n",
    "# replace to politics\n",
    "df['label'].replace({'talk.politics.misc':'politics','talk.politics.guns':'politics',\n",
    "                     'talk.politics.mideast':'politics'}, inplace=True)\n",
    "                    \n",
    "# replace to sport\n",
    "df['label'].replace({'rec.sport.hockey':'sport','rec.sport.baseball':'sport'}, inplace=True)\n",
    "                    \n",
    "# replace to religion\n",
    "df['label'].replace({'soc.religion.christian':'religion','talk.religion.misc':'religion'}, inplace=True)\n",
    "                    \n",
    "# replace to computer\n",
    "df['label'].replace({'comp.windows.x':'computer','comp.sys.ibm.pc.hardware':'computer',\n",
    "                    'comp.os.ms-windows.misc':'computer','comp.graphics':'computer',\n",
    "                    'comp.sys.mac.hardware':'computer'}, inplace=True)  \n",
    "# replace to sales\n",
    "df['label'].replace({'misc.forsale':'sales'}, inplace=True)\n",
    "\n",
    "# replace to automobile\n",
    "df['label'].replace({'rec.autos':'automobile','rec.motorcycles':'automobile'}, inplace=True)\n",
    "\n",
    "# replace to science\n",
    "df['label'].replace({'sci.crypt':'science','sci.electronics':'science','sci.space':'science'}, inplace=True)\n",
    "\n",
    "# replace to medicine\n",
    "df['label'].replace({'sci.med':'medicine'}, inplace=True)\n",
    "\n",
    "# Apply word count on text data:\n",
    "df['Number_of_words'] = df['text'].apply(lambda x:len(str(x).split()))\n",
    "\n",
    "# Drop all words that equal 0:\n",
    "no_text = df[df['Number_of_words']==0]\n",
    "\n",
    "# drop these rows\n",
    "df.drop(no_text.index,inplace=True)\n",
    "\n",
    "# cleaning the text:\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "# Applying the cleaning function to  datasets\n",
    "df['cleaned_text'] = df['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# Encode labels in column 'species'.\n",
    "df['target']= label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features not needed:\n",
    "df.reindex(columns = ['text','Number_of_words','cleaned_text','label','target'])\n",
    "df.drop(['text','Number_of_words'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11014 entries, 0 to 11313\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   label         11014 non-null  object\n",
      " 1   cleaned_text  11014 non-null  object\n",
      " 2   target        11014 non-null  int32 \n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 301.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automobile</td>\n",
       "      <td>i was wondering if anyone out there could enli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>a fair number of brave souls who upgraded thei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                       cleaned_text  target\n",
       "0  automobile  i was wondering if anyone out there could enli...       1\n",
       "1    computer  a fair number of brave souls who upgraded thei...       2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifical Machine Learning Research & Development\n",
    "- [Example](https://www.kaggle.com/rashmiek99/restaurant-review)\n",
    "- [Pytorch-LSTM](https://www.kaggle.com/ludovicocuoghi/detecting-bullying-tweets-w-pytorch-bi-lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Place holder for future NLP processing to test ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe and NLP processing for ML models:\n",
    "# Copy dataframe for ML model R&D:\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Tokenize Text:\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Removing Stopwords:\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "# Lemmatization:\n",
    "lem = WordNetLemmatizer()\n",
    "def lem_word(x):\n",
    "    return [lem.lemmatize(w) for w in x]\n",
    "\n",
    "def combine_text(list_of_text):\n",
    "\n",
    "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
    "    \n",
    "    combined_text = ' '.join(list_of_text)\n",
    "    return combined_text\n",
    "\n",
    "# Apply NLP functions to dataframe:\n",
    "df_ml['tokens'] = df_ml['cleaned_text'].apply(lambda x:tokenizer.tokenize(x))\n",
    "df_ml['stopwordremove_tokens'] = df_ml['tokens'].apply(lambda x : remove_stopwords(x))\n",
    "df_ml['lemmatized_text'] = df_ml['stopwordremove_tokens'].apply(lem_word)    \n",
    "df_ml['final_text'] = df_ml['lemmatized_text'].apply(lambda x : combine_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>final_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automobile</td>\n",
       "      <td>wondering anyone could enlighten car sawthe da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>fair number brave soul upgraded si clock oscil...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>well folk mac plus finally gave ghost weekend ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>computer</td>\n",
       "      <td>weiteks addressphone number id like get inform...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>article tombakerworldstdcom tom bakermy unders...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>medicine</td>\n",
       "      <td>dn nyedacnsvaxuwecedu david nyedn neurologydn ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>computer</td>\n",
       "      <td>old mac mac plus problemtheir screen blank som...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>computer</td>\n",
       "      <td>installed cpu clone motherboard tried mounting...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>computer</td>\n",
       "      <td>wouldnt require hypersphere point specifiesa s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>automobile</td>\n",
       "      <td>stolen pasadena pm white honda california plat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                         final_text  target\n",
       "0      automobile  wondering anyone could enlighten car sawthe da...       1\n",
       "1        computer  fair number brave soul upgraded si clock oscil...       2\n",
       "2        computer  well folk mac plus finally gave ghost weekend ...       2\n",
       "3        computer  weiteks addressphone number id like get inform...       2\n",
       "4         science  article tombakerworldstdcom tom bakermy unders...       7\n",
       "...           ...                                                ...     ...\n",
       "11309    medicine  dn nyedacnsvaxuwecedu david nyedn neurologydn ...       3\n",
       "11310    computer  old mac mac plus problemtheir screen blank som...       2\n",
       "11311    computer  installed cpu clone motherboard tried mounting...       2\n",
       "11312    computer  wouldnt require hypersphere point specifiesa s...       2\n",
       "11313  automobile  stolen pasadena pm white honda california plat...       1\n",
       "\n",
       "[11014 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop features not needed:\n",
    "df_ml.drop(['cleaned_text','tokens','stopwordremove_tokens','lemmatized_text'], axis=1, inplace=True)\n",
    "df_ml.reindex(columns = ['label','final_text','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cv = CountVectorizer(max_features= 2000)\n",
    "X= cv.fit_transform(df_ml['final_text']).toarray()\n",
    "y= df_ml['target']\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.25,stratify=y,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***RandomForest Classifier Model***\n",
      "Accuracy Score: 65.94 %\n",
      "Confusion Matrix\n",
      "[[ 13   7  17   2  31  37   1   1   8]\n",
      " [  0 165  50   1  20   5  10  15  20]\n",
      " [  0  12 643   0  11   3  13  13  22]\n",
      " [  0   8  29  69  19   2   1  10   6]\n",
      " [  0  17  45   1 285   4   4  14  14]\n",
      " [  3   4  21   2  34 158   0   4  12]\n",
      " [  0   7  53   0   3   2  65   6   8]\n",
      " [  0  21 148   2  42   4   5 191  21]\n",
      " [  2  10  25   0  17   1   0   8 227]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"***RandomForest Classifier Model***\")\n",
    "rfc_model = RandomForestClassifier(n_estimators=1000,criterion='entropy')\n",
    "rfc_model.fit(x_train,y_train)\n",
    "y_pred = rfc_model.predict(x_test)\n",
    "rfc_acc_score= accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy Score:\", round(rfc_acc_score * 100,2),\"%\")\n",
    "print(\"Confusion Matrix\")\n",
    "rfc_cm = confusion_matrix(y_test, y_pred)\n",
    "print(rfc_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Naive Bayes Model***\n",
      "Accuracy Score: 45.32 %\n",
      "Confusion Matrix\n",
      "[[ 58   2   0   0  14  23  17   0   3]\n",
      " [ 23 117   9   5  11   5  84   7  25]\n",
      " [ 31  36 311  79   1   3 217  17  22]\n",
      " [ 27   5   3  63   9  11  15   8   3]\n",
      " [ 56  28   1  13 148  54  40  16  28]\n",
      " [ 73   2   3   5  27  97  15   1  15]\n",
      " [  3  11  23   7   5   2  84   5   4]\n",
      " [ 34  36  41  29   5  14  68 187  20]\n",
      " [ 25   6   0   6  17   1  48   4 183]]\n",
      "Confusion matrix : \n",
      " [[117  23]\n",
      " [  2  58]]\n",
      "Outcome values : \n",
      " 117 23 2 58\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.41      0.44       286\n",
      "           0       0.18      0.50      0.26       117\n",
      "\n",
      "   micro avg       0.31      0.43      0.36       403\n",
      "   macro avg       0.33      0.45      0.35       403\n",
      "weighted avg       0.39      0.43      0.39       403\n",
      "\n",
      "Wall time: 887 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "print(\"***Naive Bayes Model***\")\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train,y_train)\n",
    "y_pred = gnb_model.predict(x_test)\n",
    "gnb_acc_score= accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy Score:\", round(gnb_acc_score * 100,2),\"%\")\n",
    "print(\"Confusion Matrix\")\n",
    "gnb_cm = confusion_matrix(y_test, y_pred)\n",
    "print(gnb_cm)\n",
    "\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,y_pred, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(y_test,y_pred,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,y_pred,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer       2866\n",
       "science        1734\n",
       "politics       1534\n",
       "sport          1160\n",
       "automobile     1145\n",
       "religion        952\n",
       "medicine        578\n",
       "sales           577\n",
       "alt.atheism     468\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts for labeled features:\n",
    "df_ml['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '              precision    recall  f1-score   support\\n\\n           1       0.48      0.41      0.44       286\\n           0       0.18      0.50      0.26       117\\n\\n   micro avg       0.31      0.43      0.36       403\\n   macro avg       0.33      0.45      0.35       403\\nweighted avg       0.39      0.43      0.39       403\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-cbed5850ceb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Plotting the confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confusion Matrix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Actal Values'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \"\"\"\n\u001b[0;32m    534\u001b[0m     \u001b[1;31m# Initialize the plotter object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0m\u001b[0;32m    536\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                           yticklabels, mask)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;31m# Determine good default values for the colormapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[0m\u001b[0;32m    156\u001b[0m                                     cmap, center, robust)\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[1;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;31m# plot_data is a np.ma.array instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mcalc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvmin\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrobust\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '              precision    recall  f1-score   support\\n\\n           1       0.48      0.41      0.44       286\\n           0       0.18      0.50      0.26       117\\n\\n   micro avg       0.31      0.43      0.36       403\\n   macro avg       0.33      0.45      0.35       403\\nweighted avg       0.39      0.43      0.39       403\\n'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "cm_df = pd.DataFrame(matrix,\n",
    "                     index = ['computer','science','politics','sport','automobile','religion','medicine','sales','alt.atheism'], \n",
    "                     columns = ['computer','science','politics','sport','automobile','religion','medicine','sales','alt.atheism'])\n",
    "\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('\\nPredicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae9258babb9dc6183a521d7a445c874d7696eb0fb582154c3a2ca8b33699b65d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
