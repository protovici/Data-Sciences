{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "tq() ### Library Importing Is Complete. ###: 100%|██████████| 20/20 [00:10<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####  IMPORTS COMPLETE  #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, plot_confusion_matrix, confusion_matrix, f1_score\n",
    "from statistics import mean\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Dropout\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm as tq\n",
    "import time\n",
    "for i in tq(range(20), desc = 'tq() ### Library Importing Is Complete. ###'):\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print('#####  IMPORTS COMPLETE  #####')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset ='train', \n",
    "                             remove=('headers', 'footers', 'quotes'), \n",
    "                             shuffle=True, \n",
    "                             random_state=42)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = dataset.data\n",
    "df['source'] = dataset.target\n",
    "\n",
    "label = []\n",
    "\n",
    "for i in df['source']:\n",
    "    label.append(dataset.target_names[i])\n",
    "\n",
    "df['label']=label\n",
    "\n",
    "# Remove source feature as label will be encoded for dependant:\n",
    "df.drop(['source'], axis = 1, inplace = True)\n",
    "\n",
    "# replace to politics\n",
    "df['label'].replace({'talk.politics.misc':'politics','talk.politics.guns':'politics',\n",
    "                     'talk.politics.mideast':'politics'}, inplace=True)\n",
    "                    \n",
    "# replace to sport\n",
    "df['label'].replace({'rec.sport.hockey':'sport','rec.sport.baseball':'sport'}, inplace=True)\n",
    "                    \n",
    "# replace to religion\n",
    "df['label'].replace({'soc.religion.christian':'religion','talk.religion.misc':'religion'}, inplace=True)\n",
    "                    \n",
    "# replace to computer\n",
    "df['label'].replace({'comp.windows.x':'computer','comp.sys.ibm.pc.hardware':'computer',\n",
    "                    'comp.os.ms-windows.misc':'computer','comp.graphics':'computer',\n",
    "                    'comp.sys.mac.hardware':'computer'}, inplace=True)  \n",
    "# replace to sales\n",
    "df['label'].replace({'misc.forsale':'sales'}, inplace=True)\n",
    "\n",
    "# replace to automobile\n",
    "df['label'].replace({'rec.autos':'automobile','rec.motorcycles':'automobile'}, inplace=True)\n",
    "\n",
    "# replace to science\n",
    "df['label'].replace({'sci.crypt':'science','sci.electronics':'science','sci.space':'science'}, inplace=True)\n",
    "\n",
    "# replace to medicine\n",
    "df['label'].replace({'sci.med':'medicine'}, inplace=True)\n",
    "\n",
    "# Apply word count on text data:\n",
    "df['Number_of_words'] = df['text'].apply(lambda x:len(str(x).split()))\n",
    "\n",
    "# Drop all words that equal 0:\n",
    "no_text = df[df['Number_of_words']==0]\n",
    "\n",
    "# drop these rows\n",
    "df.drop(no_text.index,inplace=True)\n",
    "\n",
    "# cleaning the text:\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "# Applying the cleaning function to  datasets\n",
    "df['cleaned_text'] = df['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# Encode labels in column 'species'.\n",
    "df['target']= label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features not needed:\n",
    "df.reindex(columns = ['text','Number_of_words','cleaned_text','label','target'])\n",
    "df.drop(['text','Number_of_words'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11014 entries, 0 to 11313\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   label         11014 non-null  object\n",
      " 1   cleaned_text  11014 non-null  object\n",
      " 2   target        11014 non-null  int32 \n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 301.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automobile</td>\n",
       "      <td>i was wondering if anyone out there could enli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>a fair number of brave souls who upgraded thei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                       cleaned_text  target\n",
       "0  automobile  i was wondering if anyone out there could enli...       1\n",
       "1    computer  a fair number of brave souls who upgraded thei...       2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifical Machine Learning Research & Development\n",
    "- [Example](https://www.kaggle.com/rashmiek99/restaurant-review)\n",
    "- [Pytorch-LSTM](https://www.kaggle.com/ludovicocuoghi/detecting-bullying-tweets-w-pytorch-bi-lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Place holder for future NLP processing to test ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe and NLP processing for ML models:\n",
    "# Copy dataframe for ML model R&D:\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Tokenize Text:\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Removing Stopwords:\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "# Lemmatization:\n",
    "lem = WordNetLemmatizer()\n",
    "def lem_word(x):\n",
    "    return [lem.lemmatize(w) for w in x]\n",
    "\n",
    "def combine_text(list_of_text):\n",
    "\n",
    "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
    "    \n",
    "    combined_text = ' '.join(list_of_text)\n",
    "    return combined_text\n",
    "\n",
    "# Apply NLP functions to dataframe:\n",
    "df_ml['tokens'] = df_ml['cleaned_text'].apply(lambda x:tokenizer.tokenize(x))\n",
    "df_ml['stopwordremove_tokens'] = df_ml['tokens'].apply(lambda x : remove_stopwords(x))\n",
    "df_ml['lemmatized_text'] = df_ml['stopwordremove_tokens'].apply(lem_word)    \n",
    "df_ml['final_text'] = df_ml['lemmatized_text'].apply(lambda x : combine_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>final_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automobile</td>\n",
       "      <td>wondering anyone could enlighten car sawthe da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>fair number brave soul upgraded si clock oscil...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>well folk mac plus finally gave ghost weekend ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>computer</td>\n",
       "      <td>weiteks addressphone number id like get inform...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>article tombakerworldstdcom tom bakermy unders...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>medicine</td>\n",
       "      <td>dn nyedacnsvaxuwecedu david nyedn neurologydn ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>computer</td>\n",
       "      <td>old mac mac plus problemtheir screen blank som...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>computer</td>\n",
       "      <td>installed cpu clone motherboard tried mounting...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>computer</td>\n",
       "      <td>wouldnt require hypersphere point specifiesa s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>automobile</td>\n",
       "      <td>stolen pasadena pm white honda california plat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                         final_text  target\n",
       "0      automobile  wondering anyone could enlighten car sawthe da...       1\n",
       "1        computer  fair number brave soul upgraded si clock oscil...       2\n",
       "2        computer  well folk mac plus finally gave ghost weekend ...       2\n",
       "3        computer  weiteks addressphone number id like get inform...       2\n",
       "4         science  article tombakerworldstdcom tom bakermy unders...       7\n",
       "...           ...                                                ...     ...\n",
       "11309    medicine  dn nyedacnsvaxuwecedu david nyedn neurologydn ...       3\n",
       "11310    computer  old mac mac plus problemtheir screen blank som...       2\n",
       "11311    computer  installed cpu clone motherboard tried mounting...       2\n",
       "11312    computer  wouldnt require hypersphere point specifiesa s...       2\n",
       "11313  automobile  stolen pasadena pm white honda california plat...       1\n",
       "\n",
       "[11014 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop features not needed:\n",
    "df_ml.drop(['cleaned_text','tokens','stopwordremove_tokens','lemmatized_text'], axis=1, inplace=True)\n",
    "df_ml.reindex(columns = ['label','final_text','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cv = CountVectorizer(max_features= 2000)\n",
    "X= cv.fit_transform(df_ml['final_text']).toarray()\n",
    "y= df_ml['target']\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.25,stratify=y,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***RandomForest Classifier Model***\n",
      "Accuracy Score: 65.94 %\n",
      "Confusion Matrix\n",
      "[[ 13   7  17   2  31  37   1   1   8]\n",
      " [  0 165  50   1  20   5  10  15  20]\n",
      " [  0  12 643   0  11   3  13  13  22]\n",
      " [  0   8  29  69  19   2   1  10   6]\n",
      " [  0  17  45   1 285   4   4  14  14]\n",
      " [  3   4  21   2  34 158   0   4  12]\n",
      " [  0   7  53   0   3   2  65   6   8]\n",
      " [  0  21 148   2  42   4   5 191  21]\n",
      " [  2  10  25   0  17   1   0   8 227]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"***RandomForest Classifier Model***\")\n",
    "rfc_model = RandomForestClassifier(n_estimators=1000,criterion='entropy')\n",
    "rfc_model.fit(x_train,y_train)\n",
    "y_pred = rfc_model.predict(x_test)\n",
    "rfc_acc_score= accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy Score:\", round(rfc_acc_score * 100,2),\"%\")\n",
    "print(\"Confusion Matrix\")\n",
    "rfc_cm = confusion_matrix(y_test, y_pred)\n",
    "print(rfc_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Naive Bayes Model***\n",
      "Accuracy Score: 45.32 %\n",
      "Confusion Matrix\n",
      "[[ 58   2   0   0  14  23  17   0   3]\n",
      " [ 23 117   9   5  11   5  84   7  25]\n",
      " [ 31  36 311  79   1   3 217  17  22]\n",
      " [ 27   5   3  63   9  11  15   8   3]\n",
      " [ 56  28   1  13 148  54  40  16  28]\n",
      " [ 73   2   3   5  27  97  15   1  15]\n",
      " [  3  11  23   7   5   2  84   5   4]\n",
      " [ 34  36  41  29   5  14  68 187  20]\n",
      " [ 25   6   0   6  17   1  48   4 183]]\n",
      "Wall time: 832 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "print(\"***Naive Bayes Model***\")\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train,y_train)\n",
    "y_pred = gnb_model.predict(x_test)\n",
    "gnb_acc_score= accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy Score:\", round(gnb_acc_score * 100,2),\"%\")\n",
    "print(\"Confusion Matrix\")\n",
    "gnb_cm = confusion_matrix(y_test, y_pred)\n",
    "print(gnb_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae9258babb9dc6183a521d7a445c874d7696eb0fb582154c3a2ca8b33699b65d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
